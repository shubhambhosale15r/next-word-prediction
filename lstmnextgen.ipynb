{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T05:51:40.650066Z",
     "iopub.status.busy": "2025-01-07T05:51:40.649762Z",
     "iopub.status.idle": "2025-01-07T05:51:43.901794Z",
     "shell.execute_reply": "2025-01-07T05:51:43.900861Z",
     "shell.execute_reply.started": "2025-01-07T05:51:40.650043Z"
    },
    "id": "W66FNSSRsLha",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pickle\n",
    "import re\n",
    "import string\n",
    "from string import digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "execution": {
     "iopub.execute_input": "2025-01-07T05:52:03.213178Z",
     "iopub.status.busy": "2025-01-07T05:52:03.212579Z",
     "iopub.status.idle": "2025-01-07T05:52:03.332012Z",
     "shell.execute_reply": "2025-01-07T05:52:03.331160Z",
     "shell.execute_reply.started": "2025-01-07T05:52:03.213147Z"
    },
    "id": "mpWmp2DGwCj3",
    "outputId": "484dafb3-1f07-4d69-aef2-dab7603814d8",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>They enjoyed a lazy afternoon at home.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>He learned to play the piano in his spare time.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The birds sang sweetly in the early morning.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>They visited an art museum to see the new exhi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He went to the store to buy some fresh produce.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0             They enjoyed a lazy afternoon at home.\n",
       "1    He learned to play the piano in his spare time.\n",
       "2       The birds sang sweetly in the early morning.\n",
       "3  They visited an art museum to see the new exhi...\n",
       "4    He went to the store to buy some fresh produce."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/newdata33/newdata.txt\", sep='\\t', header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-01-07T05:52:06.563144Z",
     "iopub.status.busy": "2025-01-07T05:52:06.562854Z",
     "iopub.status.idle": "2025-01-07T05:52:06.575635Z",
     "shell.execute_reply": "2025-01-07T05:52:06.574499Z",
     "shell.execute_reply.started": "2025-01-07T05:52:06.563122Z"
    },
    "id": "14JF6aZlwl-Z",
    "outputId": "e3c24d08-c0eb-40db-993e-07ccd73804ff",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48320 entries, 0 to 48319\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       48320 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 377.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T05:52:11.637705Z",
     "iopub.status.busy": "2025-01-07T05:52:11.637361Z",
     "iopub.status.idle": "2025-01-07T05:52:12.231416Z",
     "shell.execute_reply": "2025-01-07T05:52:12.230736Z",
     "shell.execute_reply.started": "2025-01-07T05:52:11.637679Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Lowercase all characters\n",
    "df[0] = df[0].apply(lambda x: x.lower())\n",
    "\n",
    "# Remove single and double quotes\n",
    "df[0] = df[0].apply(lambda x: re.sub(r\"[\\\"']\", '', x))\n",
    "\n",
    "# Set of all special characters\n",
    "exclude = set(string.punctuation)\n",
    "# Remove all the special characters\n",
    "df[0] = df[0].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "\n",
    "# Remove all numbers from text\n",
    "remove_digits = str.maketrans('', '', digits)\n",
    "df[0] = df[0].apply(lambda x: x.translate(remove_digits))\n",
    "\n",
    "# Remove extra spaces\n",
    "df[0] = df[0].apply(lambda x: x.strip())\n",
    "df[0] = df[0].apply(lambda x: re.sub(\" +\", \" \", x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T05:52:14.669751Z",
     "iopub.status.busy": "2025-01-07T05:52:14.669394Z",
     "iopub.status.idle": "2025-01-07T05:52:14.677341Z",
     "shell.execute_reply": "2025-01-07T05:52:14.676283Z",
     "shell.execute_reply.started": "2025-01-07T05:52:14.669726Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>they enjoyed a lazy afternoon at home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>he learned to play the piano in his spare time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the birds sang sweetly in the early morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>they visited an art museum to see the new exhi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>he went to the store to buy some fresh produce</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0              they enjoyed a lazy afternoon at home\n",
       "1     he learned to play the piano in his spare time\n",
       "2        the birds sang sweetly in the early morning\n",
       "3  they visited an art museum to see the new exhi...\n",
       "4     he went to the store to buy some fresh produce"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-01-07T05:52:20.463358Z",
     "iopub.status.busy": "2025-01-07T05:52:20.462989Z",
     "iopub.status.idle": "2025-01-07T05:52:21.063926Z",
     "shell.execute_reply": "2025-01-07T05:52:21.063116Z",
     "shell.execute_reply.started": "2025-01-07T05:52:20.463315Z"
    },
    "id": "3khpp9unzGRC",
    "outputId": "018c4b7f-27c1-435c-e090-c1688cd0d3d8",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words: 19122\n"
     ]
    }
   ],
   "source": [
    "# Assuming the text data is in the first column\n",
    "text_data = df[0].astype(str).tolist()  # Convert column to a list of strings\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text_data)\n",
    "print(f\"Number of unique words: {len(tokenizer.word_index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eeGR_46P03_O",
    "outputId": "d3731a73-50a2-4565-be72-b9a035a895ca",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-01-07T05:52:23.299129Z",
     "iopub.status.busy": "2025-01-07T05:52:23.298846Z",
     "iopub.status.idle": "2025-01-07T05:52:23.314996Z",
     "shell.execute_reply": "2025-01-07T05:52:23.314340Z",
     "shell.execute_reply.started": "2025-01-07T05:52:23.299107Z"
    },
    "id": "fnmsOROm2j0O",
    "outputId": "d4c8275a-7daa-46f9-a171-bb5180dba897",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save tokenizer\n",
    "with open('tokenizer.pkl', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-01-07T05:53:35.471866Z",
     "iopub.status.busy": "2025-01-07T05:53:35.471545Z",
     "iopub.status.idle": "2025-01-07T05:53:36.712211Z",
     "shell.execute_reply": "2025-01-07T05:53:36.711472Z",
     "shell.execute_reply.started": "2025-01-07T05:53:35.471844Z"
    },
    "id": "A0XzURXuFPPl",
    "outputId": "310ec81d-ee7e-47f3-8f21-6413f537e5e1",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of input sequences: 437518\n"
     ]
    }
   ],
   "source": [
    "# Assuming text data is in the first column of the DataFrame (df[0])\n",
    "text_data = df[0].astype(str).tolist()  # Convert the column to a list of strings\n",
    "\n",
    "# Generate subsequences\n",
    "input_sequences = []\n",
    "for sentence in text_data:\n",
    "    tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
    "    for i in range(1, len(tokenized_sentence)):\n",
    "        input_sequences.append(tokenized_sentence[:i+1])\n",
    "\n",
    "print(f\"Number of input sequences: {len(input_sequences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-N3yfvSr0DiE",
    "outputId": "4fc0611e-9bb5-4fde-82c2-39402a404704",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-01-07T05:53:38.513500Z",
     "iopub.status.busy": "2025-01-07T05:53:38.513147Z",
     "iopub.status.idle": "2025-01-07T05:53:38.567603Z",
     "shell.execute_reply": "2025-01-07T05:53:38.566495Z",
     "shell.execute_reply.started": "2025-01-07T05:53:38.513464Z"
    },
    "id": "IuF2ZS500dLH",
    "outputId": "5a3db000-4548-4c8e-f226-d5c81951ab7a",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#max length of sentence\n",
    "max_len = max([len(x) for x in input_sequences])\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-01-07T05:53:41.154065Z",
     "iopub.status.busy": "2025-01-07T05:53:41.153750Z",
     "iopub.status.idle": "2025-01-07T05:53:41.999456Z",
     "shell.execute_reply": "2025-01-07T05:53:41.998527Z",
     "shell.execute_reply.started": "2025-01-07T05:53:41.154037Z"
    },
    "id": "Heq8PD3g13XX",
    "outputId": "54a18fe2-427b-4d02-99a4-e82b71dcab5d",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   0,   5,  30],\n",
       "       [  0,   0,   0, ...,   5,  30,   2],\n",
       "       [  0,   0,   0, ...,  30,   2, 597],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,  32,  10,   1],\n",
       "       [  0,   0,   0, ...,  10,   1,  98],\n",
       "       [  0,   0,   0, ...,   1,  98, 534]], dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#zero padding\n",
    "padded_input_sequences = pad_sequences(input_sequences, maxlen=max_len, padding='pre')\n",
    "padded_input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-01-07T05:53:46.401133Z",
     "iopub.status.busy": "2025-01-07T05:53:46.400835Z",
     "iopub.status.idle": "2025-01-07T05:53:46.405647Z",
     "shell.execute_reply": "2025-01-07T05:53:46.404689Z",
     "shell.execute_reply.started": "2025-01-07T05:53:46.401110Z"
    },
    "id": "6obqLZCc-52_",
    "outputId": "5411795a-3bc3-450e-b2a2-f9adfc773060",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(437518, 20) (437518,)\n"
     ]
    }
   ],
   "source": [
    "# Prepare X and y using CountVectorizer\n",
    "X = padded_input_sequences[:, :-1]\n",
    "y = padded_input_sequences[:, -1]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T05:53:57.807468Z",
     "iopub.status.busy": "2025-01-07T05:53:57.807129Z",
     "iopub.status.idle": "2025-01-07T05:53:59.060493Z",
     "shell.execute_reply": "2025-01-07T05:53:59.059649Z",
     "shell.execute_reply.started": "2025-01-07T05:53:57.807439Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19123"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert y to categorical\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "y = tf.keras.utils.to_categorical(y, num_classes=vocab_size)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T05:54:06.444820Z",
     "iopub.status.busy": "2025-01-07T05:54:06.444508Z",
     "iopub.status.idle": "2025-01-07T05:54:06.450148Z",
     "shell.execute_reply": "2025-01-07T05:54:06.449388Z",
     "shell.execute_reply.started": "2025-01-07T05:54:06.444795Z"
    },
    "id": "jXV7i-XgA-w8",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "execution": {
     "iopub.execute_input": "2025-01-07T05:58:39.425430Z",
     "iopub.status.busy": "2025-01-07T05:58:39.425115Z",
     "iopub.status.idle": "2025-01-07T05:58:39.499277Z",
     "shell.execute_reply": "2025-01-07T05:58:39.498479Z",
     "shell.execute_reply.started": "2025-01-07T05:58:39.425386Z"
    },
    "id": "f4Xm4EpPGW5o",
    "outputId": "2e62607f-716c-40c5-db2d-62c767faa7ea",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,912,300</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">150,600</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">100,400</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19123</span>)               │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,931,423</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m100\u001b[0m)             │       \u001b[38;5;34m1,912,300\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m150\u001b[0m)             │         \u001b[38;5;34m150,600\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │         \u001b[38;5;34m100,400\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19123\u001b[0m)               │       \u001b[38;5;34m1,931,423\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,094,723</span> (15.62 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,094,723\u001b[0m (15.62 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,094,723</span> (15.62 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,094,723\u001b[0m (15.62 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(X.shape[1],)))\n",
    "model.add(Embedding(vocab_size, 100))\n",
    "model.add(LSTM(150, return_sequences=True))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "#compile\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T05:58:41.147182Z",
     "iopub.status.busy": "2025-01-07T05:58:41.146883Z",
     "iopub.status.idle": "2025-01-07T05:58:41.152432Z",
     "shell.execute_reply": "2025-01-07T05:58:41.151341Z",
     "shell.execute_reply.started": "2025-01-07T05:58:41.147159Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the batch generator function\n",
    "def generate_batch(X, y, batch_size=64):\n",
    "    '''Generate a batch of data for training.'''\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, X.shape[1]), dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, y.shape[1]), dtype='float32')\n",
    "            for i, (input_seq, target_seq) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                encoder_input_data[i] = input_seq\n",
    "                decoder_target_data[i] = target_seq\n",
    "            yield encoder_input_data, decoder_target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T05:58:43.379609Z",
     "iopub.status.busy": "2025-01-07T05:58:43.379261Z",
     "iopub.status.idle": "2025-01-07T05:58:43.383669Z",
     "shell.execute_reply": "2025-01-07T05:58:43.382799Z",
     "shell.execute_reply.started": "2025-01-07T05:58:43.379573Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='best_model.keras',  # File path to save the model\n",
    "    monitor='val_loss',        # Metric to monitor (e.g., validation loss)\n",
    "    save_best_only=True,       # Save only the best model\n",
    "    mode='min',                # Mode for val_loss: minimize it\n",
    "    verbose=1                  # Print messages when saving the model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T05:58:44.405335Z",
     "iopub.status.busy": "2025-01-07T05:58:44.405071Z",
     "iopub.status.idle": "2025-01-07T05:58:44.409227Z",
     "shell.execute_reply": "2025-01-07T05:58:44.408323Z",
     "shell.execute_reply.started": "2025-01-07T05:58:44.405313Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='loss',  # You can also use 'val_loss' if you have validation data\n",
    "    patience=3,      # Stop training after 5 epochs with no improvement\n",
    "    restore_best_weights=True  # Restore the best weights once training stops\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T05:58:46.563075Z",
     "iopub.status.busy": "2025-01-07T05:58:46.562784Z",
     "iopub.status.idle": "2025-01-07T07:42:31.388667Z",
     "shell.execute_reply": "2025-01-07T07:42:31.387815Z",
     "shell.execute_reply.started": "2025-01-07T05:58:46.563051Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 30ms/step - accuracy: 0.1017 - loss: 6.6479\n",
      "Epoch 2/60\n",
      "\u001b[1m   3/3418\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:42\u001b[0m 30ms/step - accuracy: 0.2144 - loss: 1.0251"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/callbacks/model_checkpoint.py:206: UserWarning: Can save best model only with val_loss available, skipping.\n",
      "  self._save_model(epoch=epoch, batch=None, logs=logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 30ms/step - accuracy: 0.1937 - loss: 5.4411\n",
      "Epoch 3/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 30ms/step - accuracy: 0.2446 - loss: 4.9853\n",
      "Epoch 4/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 30ms/step - accuracy: 0.2724 - loss: 4.6950\n",
      "Epoch 5/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 30ms/step - accuracy: 0.2864 - loss: 4.5006\n",
      "Epoch 6/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 30ms/step - accuracy: 0.2937 - loss: 4.3234\n",
      "Epoch 7/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 30ms/step - accuracy: 0.3001 - loss: 4.1866\n",
      "Epoch 8/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 30ms/step - accuracy: 0.3058 - loss: 4.0600\n",
      "Epoch 9/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 30ms/step - accuracy: 0.3122 - loss: 3.9535\n",
      "Epoch 10/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 30ms/step - accuracy: 0.3184 - loss: 3.8500\n",
      "Epoch 11/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 30ms/step - accuracy: 0.3259 - loss: 3.7459\n",
      "Epoch 12/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 30ms/step - accuracy: 0.3336 - loss: 3.6576\n",
      "Epoch 13/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 30ms/step - accuracy: 0.3415 - loss: 3.5716\n",
      "Epoch 14/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 30ms/step - accuracy: 0.3503 - loss: 3.4935\n",
      "Epoch 15/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 30ms/step - accuracy: 0.3592 - loss: 3.4158\n",
      "Epoch 16/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 30ms/step - accuracy: 0.3682 - loss: 3.3411\n",
      "Epoch 17/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 30ms/step - accuracy: 0.3768 - loss: 3.2698\n",
      "Epoch 18/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 30ms/step - accuracy: 0.3853 - loss: 3.2049\n",
      "Epoch 19/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 30ms/step - accuracy: 0.3922 - loss: 3.1461\n",
      "Epoch 20/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 30ms/step - accuracy: 0.4001 - loss: 3.0893\n",
      "Epoch 21/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 30ms/step - accuracy: 0.4069 - loss: 3.0388\n",
      "Epoch 22/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 31ms/step - accuracy: 0.4136 - loss: 2.9900\n",
      "Epoch 23/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 31ms/step - accuracy: 0.4208 - loss: 2.9343\n",
      "Epoch 24/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 30ms/step - accuracy: 0.4282 - loss: 2.8837\n",
      "Epoch 25/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 30ms/step - accuracy: 0.4351 - loss: 2.8368\n",
      "Epoch 26/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 30ms/step - accuracy: 0.4414 - loss: 2.7914\n",
      "Epoch 27/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 30ms/step - accuracy: 0.4472 - loss: 2.7529\n",
      "Epoch 28/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 30ms/step - accuracy: 0.4517 - loss: 2.7203\n",
      "Epoch 29/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 31ms/step - accuracy: 0.4537 - loss: 2.7026\n",
      "Epoch 30/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 30ms/step - accuracy: 0.4634 - loss: 2.6402\n",
      "Epoch 31/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 30ms/step - accuracy: 0.4693 - loss: 2.6021\n",
      "Epoch 32/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 30ms/step - accuracy: 0.4736 - loss: 2.5737\n",
      "Epoch 33/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 30ms/step - accuracy: 0.4777 - loss: 2.5468\n",
      "Epoch 34/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 30ms/step - accuracy: 0.4843 - loss: 2.5030\n",
      "Epoch 35/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 30ms/step - accuracy: 0.4891 - loss: 2.4677\n",
      "Epoch 36/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 30ms/step - accuracy: 0.4937 - loss: 2.4428\n",
      "Epoch 37/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 30ms/step - accuracy: 0.4971 - loss: 2.4197\n",
      "Epoch 38/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 30ms/step - accuracy: 0.4997 - loss: 2.3973\n",
      "Epoch 39/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 30ms/step - accuracy: 0.5056 - loss: 2.3615\n",
      "Epoch 40/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 30ms/step - accuracy: 0.5074 - loss: 2.3471\n",
      "Epoch 41/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 30ms/step - accuracy: 0.5116 - loss: 2.3218\n",
      "Epoch 42/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 31ms/step - accuracy: 0.5184 - loss: 2.2825\n",
      "Epoch 43/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 30ms/step - accuracy: 0.5230 - loss: 2.2577\n",
      "Epoch 44/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 30ms/step - accuracy: 0.5273 - loss: 2.2274\n",
      "Epoch 45/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 30ms/step - accuracy: 0.5304 - loss: 2.2095\n",
      "Epoch 46/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 30ms/step - accuracy: 0.5341 - loss: 2.1823\n",
      "Epoch 47/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 30ms/step - accuracy: 0.5366 - loss: 2.1661\n",
      "Epoch 48/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 30ms/step - accuracy: 0.5412 - loss: 2.1382\n",
      "Epoch 49/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 30ms/step - accuracy: 0.5442 - loss: 2.1181\n",
      "Epoch 50/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 30ms/step - accuracy: 0.5475 - loss: 2.0996\n",
      "Epoch 51/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 30ms/step - accuracy: 0.5458 - loss: 2.0999\n",
      "Epoch 52/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 30ms/step - accuracy: 0.5529 - loss: 2.0655\n",
      "Epoch 53/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 30ms/step - accuracy: 0.5500 - loss: 2.0748\n",
      "Epoch 54/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 30ms/step - accuracy: 0.5571 - loss: 2.0355\n",
      "Epoch 55/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 30ms/step - accuracy: 0.5589 - loss: 2.0251\n",
      "Epoch 56/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 30ms/step - accuracy: 0.5651 - loss: 1.9924\n",
      "Epoch 57/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 30ms/step - accuracy: 0.5686 - loss: 1.9696\n",
      "Epoch 58/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 30ms/step - accuracy: 0.5676 - loss: 1.9740\n",
      "Epoch 59/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 30ms/step - accuracy: 0.5730 - loss: 1.9413\n",
      "Epoch 60/60\n",
      "\u001b[1m3418/3418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 30ms/step - accuracy: 0.5747 - loss: 1.9342\n"
     ]
    }
   ],
   "source": [
    "batch_sizes = 128\n",
    "steps_per_epochs = len(X) // batch_sizes\n",
    "\n",
    "history = model.fit(\n",
    "    generate_batch(X, y, batch_size=batch_sizes),\n",
    "    epochs=60,\n",
    "    steps_per_epoch=steps_per_epochs,\n",
    "    verbose=1,\n",
    "    callbacks=[checkpoint_callback,early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T07:43:04.335532Z",
     "iopub.status.busy": "2025-01-07T07:43:04.335216Z",
     "iopub.status.idle": "2025-01-07T07:43:04.340750Z",
     "shell.execute_reply": "2025-01-07T07:43:04.339817Z",
     "shell.execute_reply.started": "2025-01-07T07:43:04.335506Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to predict next top 3 words with probabilities\n",
    "def predict_next_words(model, tokenizer, text, max_len, top_n=3):\n",
    "    tokenized_text = tokenizer.texts_to_sequences([text])[0]\n",
    "    padded_token_text = pad_sequences([tokenized_text], maxlen=max_len, padding='pre')\n",
    "    predictions = model.predict(padded_token_text, verbose=0)[0]\n",
    "    \n",
    "    # Get the top N predictions\n",
    "    top_indices = np.argsort(predictions)[-top_n:][::-1]\n",
    "    top_words = [(word, predictions[index]) for word, index in tokenizer.word_index.items() if index in top_indices]\n",
    "    return top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T07:45:21.212040Z",
     "iopub.status.busy": "2025-01-07T07:45:21.211755Z",
     "iopub.status.idle": "2025-01-07T07:45:21.778232Z",
     "shell.execute_reply": "2025-01-07T07:45:21.777442Z",
     "shell.execute_reply.started": "2025-01-07T07:45:21.212018Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current text: 'lets go'\n",
      "Top predictions: [('to', 0.19974668), ('on', 0.17169979), ('out', 0.21576026)]\n",
      "Current text: 'lets go to'\n",
      "Top predictions: [('the', 0.66113836), ('a', 0.020017266), ('visit', 0.140714)]\n",
      "Current text: 'lets go to the'\n",
      "Top predictions: [('beach', 0.38402003), ('farmers', 0.054403014), ('nearest', 0.09970752)]\n",
      "Current text: 'lets go to the beach'\n",
      "Top predictions: [('the', 0.018844157), ('to', 0.6291719), ('enjoying', 0.27504632)]\n",
      "Current text: 'lets go to the beach the'\n",
      "Top predictions: [('birds', 0.2208275), ('wind', 0.16478634), ('weather', 0.23065408)]\n"
     ]
    }
   ],
   "source": [
    "# Predict multiple words\n",
    "text = \"lets go\"\n",
    "for i in range(5):\n",
    "    top_predictions = predict_next_words(model, tokenizer, text, max_len, top_n=3)\n",
    "    print(f\"Current text: '{text}'\")\n",
    "    print(f\"Top predictions: {top_predictions}\")\n",
    "    next_word = top_predictions[0][0]  # Choose the word with the highest probability\n",
    "    text += \" \" + next_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T07:43:17.716183Z",
     "iopub.status.busy": "2025-01-07T07:43:17.715900Z",
     "iopub.status.idle": "2025-01-07T07:43:17.838146Z",
     "shell.execute_reply": "2025-01-07T07:43:17.837486Z",
     "shell.execute_reply.started": "2025-01-07T07:43:17.716160Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save('model/model.h5')\n",
    "\n",
    "# Save tokenizer\n",
    "with open('model/tokenizer.pkl', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6437807,
     "sourceId": 10391423,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30827,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
